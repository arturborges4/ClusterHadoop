# ClusterHadoop
Cluster Hadoop utilizando VMs Ubuntu Server no Proxmox


üñ•Ô∏èConfigura√ß√£o do Cluster
<h1>1. Fun√ß√£o de cada n√≥ no cluster Hadoop:</h1>

<h3>NameNode (Master):</h3>

√â respons√°vel por gerenciar o metadata do sistema de arquivos distribu√≠do HDFS (ex.: nomes dos arquivos, blocos, localiza√ß√µes nos DataNodes).
Coordena as opera√ß√µes de leitura/escrita e √© essencial para a opera√ß√£o do cluster.

<h3>DataNode (Slaves):</h3>

Armazenam os dados reais em blocos.
Respondem √†s solicita√ß√µes do NameNode para leitura, escrita e replica√ß√£o de dados.

<h3>ResourceManager (Master):</h3>

Gerencia os recursos do cluster para execu√ß√£o de aplica√ß√µes distribu√≠das.
Trabalha com o NodeManager para alocar cont√™ineres e monitorar tarefas.

<h3>NodeManager (Slaves):</h3>

Executa tarefas atribu√≠das pelo ResourceManager.
Monitora o uso de recursos (CPU, mem√≥ria) em cada n√≥.



<h1>2. Configura√ß√µes alteradas nos arquivos do Hadoop e motivos:</h1>

<h3>core-site.xml</h3>
fs.defaultFS: Configurado com o endere√ßo do NameNode (hdfs://192.168.100.193:9000) para centralizar a comunica√ß√£o.
Motivo: Informar o local do sistema de arquivos HDFS para todas as opera√ß√µes.

<h3>hdfs-site.xml</h3>
dfs.namenode.name.dir e dfs.datanode.data.dir: Diret√≥rios locais configurados para armazenar os dados do NameNode e DataNodes.
dfs.replication: Definido como 3, para garantir redund√¢ncia dos dados.
Motivo: Configurar o armazenamento f√≠sico e a replica√ß√£o dos dados no cluster.

<h3>yarn-site.xml</h3>
yarn.resourcemanager.hostname: Configurado com o endere√ßo do ResourceManager (master).
yarn.nodemanager.aux-services: Ativou o servi√ßo de shuffle necess√°rio para a execu√ß√£o de jobs no YARN.
Motivo: Permitir que o YARN coordene a execu√ß√£o das aplica√ß√µes distribu√≠das.

<h3>slaves</h3>
Adicionados os endere√ßos dos n√≥s slave (slave1 e slave2).
Motivo: Informar ao cluster os n√≥s que devem atuar como DataNodes e NodeManagers.



<h1>Execu√ß√£o da Aplica√ß√£o</h1>
<h3>1. Etapas para executar o WordCount:</h3>

- Criei um arquivo input.txt contendo palavras simples.
- Usei o comando ```hadoop fs -mkdir``` para criar um diret√≥rio de entrada no HDFS.
- Carreguei o arquivo input.txt no HDFS com ```hadoop fs -put```
- Executei o job WordCount usando:
```hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar wordcount /user/hadoop/input /user/hadoop/output```
- Verifiquei os resultados com ```hadoop fs -cat /user/hadoop/output/part-r-00000```


<h3>2. Onde o arquivo foi enviado e como foi especificado:</h3>
O arquivo input.txt foi enviado ao HDFS no diret√≥rio /user/hadoop/input.
Na execu√ß√£o do WordCount, o diret√≥rio de entrada foi especificado como /user/hadoop/input, e o de sa√≠da foi definido como /user/hadoop/output.

<h3>3. Como o Hadoop divide e distribui as tarefas:</h3>
- O HDFS divide o arquivo de entrada em blocos (padr√£o: 128 MB).
- Cada bloco √© processado por um Map Task, atribu√≠do aos DataNodes que armazenam os blocos.
- O Reduce Task combina os resultados intermedi√°rios dos Map Tasks, produzindo a sa√≠da final.


<h3>2. Distribui√ß√£o da carga entre os n√≥s:</h3>
- O job foi distribu√≠do entre os tr√™s DataNodes, com cada n√≥ processando blocos armazenados localmente.
- Raz√µes para carga desigual
     Dados locais: O Hadoop tenta processar blocos no mesmo n√≥ onde est√£o armazenados.                                                                                                                                                       
     N√∫mero de blocos: Se o arquivo possui poucos blocos, nem todos os n√≥s ser√£o usados igualmente.                                                                                                                            
     Configura√ß√£o do cluster: Par√¢metros como n√∫mero de Map/Reduce Tasks podem limitar a paraleliza√ß√£o.
